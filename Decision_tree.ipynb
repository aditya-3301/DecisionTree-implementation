{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7b98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train Dataset ---\n",
      "Shape: (891, 12)\n",
      "Data Types:\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex              int64\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Missing Values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Statistical Summary:\n",
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  714.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.699118   \n",
      "std     257.353842    0.486592    0.836071    0.477990   14.526497   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000   20.125000   \n",
      "50%     446.000000    0.000000    3.000000    1.000000   28.000000   \n",
      "75%     668.500000    1.000000    3.000000    1.000000   38.000000   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare  \n",
      "count  891.000000  891.000000  891.000000  \n",
      "mean     0.523008    0.381594   32.204208  \n",
      "std      1.102743    0.806057   49.693429  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    7.910400  \n",
      "50%      0.000000    0.000000   14.454200  \n",
      "75%      1.000000    0.000000   31.000000  \n",
      "max      8.000000    6.000000  512.329200  \n",
      "\n",
      "First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        S  \n",
      "1          PC 17599  71.2833   C85        C  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3            113803  53.1000  C123        S  \n",
      "4            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "--- Test Dataset ---\n",
      "Shape: (418, 11)\n",
      "Data Types:\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex              int64\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Missing Values:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "Statistical Summary:\n",
      "       PassengerId      Pclass         Sex         Age       SibSp  \\\n",
      "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
      "mean   1100.500000    2.265550    0.636364   30.272590    0.447368   \n",
      "std     120.810458    0.841838    0.481622   14.181209    0.896760   \n",
      "min     892.000000    1.000000    0.000000    0.170000    0.000000   \n",
      "25%     996.250000    1.000000    0.000000   21.000000    0.000000   \n",
      "50%    1100.500000    3.000000    1.000000   27.000000    0.000000   \n",
      "75%    1204.750000    3.000000    1.000000   39.000000    1.000000   \n",
      "max    1309.000000    3.000000    1.000000   76.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  418.000000  417.000000  \n",
      "mean     0.392344   35.627188  \n",
      "std      0.981429   55.907576  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.895800  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.500000  \n",
      "max      9.000000  512.329200  \n",
      "\n",
      "First 5 rows:\n",
      "   PassengerId  Pclass                                          Name  Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    1   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
      "3          895       3                              Wirz, Mr. Albert    1   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "from typing import Union\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Mapping 'Sex' column to binary values: 1 for male, 0 for female\n",
    "train_df[\"Sex\"] = train_df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "test_df[\"Sex\"] = test_df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "\n",
    "# Display basic information for the training and test datasets\n",
    "def display_basic_info(df: pd.DataFrame, name: str):\n",
    "    print(f\"--- {name} Dataset ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Data Types:\\n{df.dtypes}\")\n",
    "    print(f\"Missing Values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Statistical Summary:\\n{df.describe()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Explore the datasets\n",
    "display_basic_info(train_df, \"Train\")\n",
    "display_basic_info(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9038658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')\n",
      "\n",
      "\n",
      "\n",
      " 0      S\n",
      "1      C\n",
      "2      S\n",
      "3      S\n",
      "4      S\n",
      "      ..\n",
      "886    S\n",
      "887    S\n",
      "888    S\n",
      "889    C\n",
      "890    Q\n",
      "Name: Embarked, Length: 891, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df=train_df.drop([\"PassengerId\",\"Ticket\",\"Cabin\"],axis = 1)\n",
    "test_df=test_df.drop([\"PassengerId\",\"Ticket\",\"Cabin\"],axis = 1)\n",
    "print(train_df.columns)\n",
    "print(test_df.columns)\n",
    "y=train_df[\"Survived\"]\n",
    "print(\"\\n\\n\\n\",train_df[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fdbd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature for total family members aboard (including the passenger)\n",
    "train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
    "test_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n",
    "\n",
    "# Fill missing Age values with the median (to avoid bias from missing data)\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].median())\n",
    "\n",
    "\n",
    "# Categorize passengers into age groups for better generalization\n",
    "train_df[\"AgeGroup\"] = pd.cut(train_df[\"Age\"], bins=[0, 12, 18, 35, 60, 80],\n",
    "                              labels=[\"Child\", \"Teen\", \"YoungAdult\", \"Adult\", \"Senior\"])\n",
    "test_df[\"AgeGroup\"] = pd.cut(test_df[\"Age\"], bins=[0, 12, 18, 35, 60, 80],\n",
    "                             labels=[\"Child\", \"Teen\", \"YoungAdult\", \"Adult\", \"Senior\"])\n",
    "\n",
    "# Extract title from the Name column\n",
    "def extract_title(name):\n",
    "    if \"Mr.\" in name:\n",
    "        return \"Mr.\"\n",
    "    elif \"Mrs.\" in name:\n",
    "        return \"Mrs.\"\n",
    "    elif \"Miss\" in name:\n",
    "        return \"Miss\"\n",
    "    elif \"Ms.\" in name:\n",
    "        return \"Ms.\"\n",
    "    elif \"Master\" in name:\n",
    "        return \"Master.\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply title extraction to Name column\n",
    "train_df[\"Name\"] = train_df[\"Name\"].apply(extract_title)\n",
    "\n",
    "# Create a feature that flags passengers traveling alone\n",
    "train_df[\"IsAlone\"] = (train_df[\"FamilySize\"] == 1).astype(int)\n",
    "test_df[\"IsAlone\"] = (test_df[\"FamilySize\"] == 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d0d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, criterion='gini') -> None:\n",
    "        self.max_depth = max_depth  # Max depth of the tree\n",
    "        self.min_samples_split = min_samples_split  # Min samples required to split\n",
    "        self.tree = None  # Final tree structure\n",
    "\n",
    "    def gini_impurity(self, y: list) -> float:\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        gini = 1 - sum((count / total) ** 2 for count in counts.values())\n",
    "        return gini\n",
    "\n",
    "    def get_thresholds(self, feature_column: list) -> list: \n",
    "        # Remove None, NaN, and \"Unknown\" values from feature_column\n",
    "        cleaned = [x for x in feature_column if x is not None and pd.notna(x) and x != \"Unknown\"]\n",
    "\n",
    "        thresholds = []\n",
    "        if len(cleaned) == 0:\n",
    "            return thresholds  # No valid values, return empty list\n",
    "\n",
    "        # Check if all cleaned values are numeric (int or float)\n",
    "        if all(isinstance(x, (int, float)) for x in cleaned):\n",
    "            # For numeric: use midpoints between sorted unique values\n",
    "            unique_values = sorted(set(cleaned))\n",
    "            for i in range(len(unique_values) - 1):\n",
    "                midpoint = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "                thresholds.append(midpoint)\n",
    "            return thresholds\n",
    "        else:\n",
    "            # For categorical: use unique categories sorted alphabetically\n",
    "            unique_categories = sorted(set(cleaned))\n",
    "            return unique_categories\n",
    "\n",
    "    def split_data(self, passengers_df: pd.DataFrame, survived: list, feature: str, threshold: float) -> tuple:\n",
    "        # Split data into left and right groups based on feature and threshold\n",
    "        passengers = passengers_df.to_dict(orient='records')\n",
    "        left_pass, left_survived = [], []\n",
    "        right_pass, right_survived = [], []\n",
    "\n",
    "        if isinstance(threshold, (int, float)):\n",
    "            for i in range(len(passengers)):\n",
    "                if passengers[i][feature] <= threshold:\n",
    "                    left_pass.append(passengers[i])\n",
    "                    left_survived.append(survived[i])\n",
    "                else:\n",
    "                    right_pass.append(passengers[i])\n",
    "                    right_survived.append(survived[i])\n",
    "        else:\n",
    "            for i in range(len(passengers)):\n",
    "                if passengers[i][feature] == threshold:\n",
    "                    right_pass.append(passengers[i])\n",
    "                    right_survived.append(survived[i])\n",
    "                else:\n",
    "                    left_pass.append(passengers[i])\n",
    "                    left_survived.append(survived[i])\n",
    "\n",
    "        return left_pass, left_survived, right_pass, right_survived\n",
    "\n",
    "    def information_gain(self, passengers_df: pd.DataFrame, survived: list, feature: str, threshold: float) -> float:\n",
    "        # Calculate info gain for a specific feature-threshold split\n",
    "        parent_gini = self.gini_impurity(survived)\n",
    "\n",
    "        left_pass, left_survived, right_pass, right_survived = self.split_data(\n",
    "            passengers_df, survived, feature, threshold)\n",
    "\n",
    "        w_left = len(left_survived) / len(survived)\n",
    "        w_right = len(right_survived) / len(survived)\n",
    "\n",
    "        g_left = self.gini_impurity(left_survived)\n",
    "        g_right = self.gini_impurity(right_survived)\n",
    "\n",
    "        info_gain = parent_gini - (w_left * g_left + w_right * g_right)\n",
    "        return info_gain\n",
    "\n",
    "    def best_split(self, passengers_df: pd.DataFrame, survived: list) -> Union[str, float, float]:\n",
    "        # Find the best feature and threshold to split on\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_info_gain = -float('inf')\n",
    "\n",
    "        for feature in passengers_df.columns:\n",
    "            thresholds = self.get_thresholds(passengers_df[feature].values)\n",
    "            for threshold in thresholds:\n",
    "                temp_info = self.information_gain(passengers_df, survived, feature, threshold)\n",
    "                if temp_info > best_info_gain:\n",
    "                    best_info_gain = temp_info\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_info_gain\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y, depth=0):\n",
    "        y=list(y)\n",
    "        # Train the tree recursively\n",
    "\n",
    "        # Stop if all labels are the same\n",
    "        if len(set(y)) == 1:\n",
    "            return {\"type\": \"leaf\", \"prediction\": y[0]} \n",
    "\n",
    "        # Stop if tree depth exceeded\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            y_list = list(y)\n",
    "            prediction = max(set(y_list), key=y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "\n",
    "        # Stop if too few samples to split\n",
    "        if len(y) < self.min_samples_split:\n",
    "            y_list = list(y)\n",
    "            prediction = max(set(y_list), key=y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "\n",
    "        # Find best feature and threshold\n",
    "        feature, threshold, gain = self.best_split(X, y)\n",
    "\n",
    "        # Split data\n",
    "        left_pass, left_y, right_pass, right_y = self.split_data(X, y, feature, threshold)\n",
    "\n",
    "        # If any side is empty, make a leaf with majority class\n",
    "        if len(left_y) == 0:\n",
    "            right_y_list = list(right_y)\n",
    "            prediction = max(set(right_y_list), key=right_y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "        if len(right_y) == 0:\n",
    "            left_y_list = list(left_y)\n",
    "            prediction = max(set(left_y_list), key=left_y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "\n",
    "        # Recursively build left and right branches\n",
    "        left_pass = pd.DataFrame(left_pass)\n",
    "        right_pass = pd.DataFrame(right_pass)\n",
    "\n",
    "        left_branch = self.fit(left_pass, left_y, depth + 1)\n",
    "        right_branch = self.fit(right_pass, right_y, depth + 1)\n",
    "\n",
    "        node = {\n",
    "            \"type\": \"node\",\n",
    "            \"feature\": feature,\n",
    "            \"threshold\": threshold,\n",
    "            \"left\": left_branch,\n",
    "            \"right\": right_branch\n",
    "        }\n",
    "\n",
    "        if depth == 0:\n",
    "            self.tree = node  # Save the root of the tree\n",
    "        return node\n",
    "\n",
    "\n",
    "    def predict_sample(self, x: dict):\n",
    "        # Predict the label for a single sample\n",
    "        node = self.tree\n",
    "        while node[\"type\"] != \"leaf\":\n",
    "            feature = node[\"feature\"]\n",
    "            threshold = node[\"threshold\"]\n",
    "\n",
    "            if isinstance(threshold, (int, float)):\n",
    "                if x[feature] <= threshold:\n",
    "                    node = node[\"left\"]\n",
    "                else:\n",
    "                    node = node[\"right\"]\n",
    "            else:\n",
    "                if x[feature] == threshold:\n",
    "                    node = node[\"right\"]\n",
    "                else:\n",
    "                    node = node[\"left\"]\n",
    "\n",
    "        return node[\"prediction\"]\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        # Predict labels for all samples\n",
    "        return [self.predict_sample(row) for _, row in X.iterrows()]\n",
    "\n",
    "X=train_df.drop([\"Survived\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8bc2a",
   "metadata": {},
   "source": [
    "Accuracy for first 29 height Trees are:\n",
    "\n",
    "[0.782, 0.76, 0.804, 0.832, 0.827, 0.827, 0.799, 0.788, 0.777, 0.782, 0.793, 0.765, 0.76, 0.771, 0.771, 0.765, 0.765, 0.76, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765]\n",
    "\n",
    "![alt text](7b4c980b-388c-4f2e-888b-698413d113f3-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24e8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=None, min_samples_split=2, max_features='sqrt'):\n",
    "        # Number of trees in the forest\n",
    "        self.n_trees = n_trees  \n",
    "        self.max_depth = max_depth  # Maximum depth of each tree\n",
    "        self.min_samples_split = min_samples_split  # Min samples to split a node\n",
    "        self.max_features = max_features  # How many features to consider at each split\n",
    "        self.trees = []  # List to hold all decision trees\n",
    "\n",
    "    def bootstrap_sample(self, X, y):\n",
    "        # Create a bootstrap sample (random sample with replacement)\n",
    "        n_samples = X.shape[0]\n",
    "        sample_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        X_sample = X.iloc[sample_indices]\n",
    "        y_sample = y.iloc[sample_indices].tolist() \n",
    "        return X_sample, y_sample\n",
    "\n",
    "    def random_feature_selection(self, total_features):\n",
    "        # Select a random subset of features to consider at each split\n",
    "        if self.max_features == 'sqrt':\n",
    "            num_features = int(sqrt(total_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            num_features = int(np.log2(total_features))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            num_features = self.max_features\n",
    "        else:\n",
    "            num_features = total_features  # Use all features if no valid option\n",
    "        \n",
    "        # Randomly pick feature indices without replacement\n",
    "        selected_features = np.random.choice(total_features, size=num_features, replace=False)\n",
    "        return selected_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Build the forest by training multiple decision trees\n",
    "        self.trees = []\n",
    "        total_features = X.shape[1]\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            # Create a new decision tree\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "\n",
    "            # Get bootstrap sample of data\n",
    "            X_sample, y_sample = self.bootstrap_sample(X, y)\n",
    "\n",
    "            # Randomly select features for this tree\n",
    "            feature_indices = self.random_feature_selection(total_features)\n",
    "            features = X.columns[feature_indices]\n",
    "\n",
    "            # Train the tree on the sample with selected features\n",
    "            tree.fit(X_sample[features], y_sample)\n",
    "\n",
    "            # Save features used by this tree (needed for prediction)\n",
    "            tree.features = features\n",
    "\n",
    "            # Add the trained tree to the forest\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict class for each sample by majority vote from all trees\n",
    "        all_tree_predictions = []\n",
    "\n",
    "        for tree in self.trees:\n",
    "            # Predict using only features this tree was trained on\n",
    "            predictions = tree.predict(X[tree.features])\n",
    "            all_tree_predictions.append(predictions)\n",
    "\n",
    "        # Transpose to group predictions by sample\n",
    "        all_tree_predictions = np.array(all_tree_predictions).T\n",
    "\n",
    "        final_predictions = []\n",
    "\n",
    "        for sample_predictions in all_tree_predictions:\n",
    "            # Count votes and pick the most common class\n",
    "            vote_counts = Counter(sample_predictions)\n",
    "            majority_vote = vote_counts.most_common(1)[0][0]\n",
    "            final_predictions.append(majority_vote)\n",
    "\n",
    "        return final_predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Predict probability distribution of classes for each sample\n",
    "        all_tree_predictions = []\n",
    "\n",
    "        for tree in self.trees:\n",
    "            predictions = tree.predict(X[tree.features])\n",
    "            all_tree_predictions.append(predictions)\n",
    "\n",
    "        all_tree_predictions = np.array(all_tree_predictions).T\n",
    "\n",
    "        probability_predictions = []\n",
    "\n",
    "        for sample_predictions in all_tree_predictions:\n",
    "            counts = Counter(sample_predictions)\n",
    "            total_votes = len(sample_predictions)\n",
    "\n",
    "            # Calculate proportion of votes for each class\n",
    "            class_probabilities = {cls: count / total_votes for cls, count in counts.items()}\n",
    "            probability_predictions.append(class_probabilities)\n",
    "\n",
    "        return probability_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69198ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the hyperparameters to train and evaluate the model (Already done)\n",
    "# BEST PARAMETERS FOUND SO FAR: Trees: 50, Max Depth: 4, Min Samples Split: 5 --> Accuracy: 0.8156]\n",
    "\n",
    "# for n_trees in n_trees_options:\n",
    "#     for max_depth in max_depth_options:\n",
    "#         for min_samples_split in min_samples_split_options:\n",
    "#             rf = RandomForest(\n",
    "#                 n_trees=n_trees,\n",
    "#                 max_depth=max_depth,\n",
    "#                 min_samples_split=min_samples_split,\n",
    "#                 max_features='sqrt'\n",
    "#             )\n",
    "#             rf.fit(X_train, y_train)\n",
    "#             preds = rf.predict(X_val)\n",
    "#             accuracy = sum(pred == true for pred, true in zip(preds, y_val)) / len(y_val)\n",
    "#             print(f\"Trees: {n_trees}, Max Depth: {max_depth}, Min Samples Split: {min_samples_split} Accuracy: {accuracy:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5026e3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Submission Preview ---\n",
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the full training set (features and labels)\n",
    "X_train_full = train_df.drop(\"Survived\", axis=1)  # Features\n",
    "y_train_full = train_df[\"Survived\"]               # Target\n",
    "\n",
    "# Prepare the test set (make sure it matches training features)\n",
    "X_test = test_df[X_train_full.columns]\n",
    "\n",
    "# Initialize the best Random Forest model found from tuning\n",
    "rf_best = RandomForest(\n",
    "    n_trees=50,\n",
    "    max_depth=4,\n",
    "    min_samples_split=5,\n",
    "    max_features='sqrt'\n",
    ")\n",
    "\n",
    "# Train the model on the entire training dataset\n",
    "rf_best.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Print the predictions as a submission format (PassengerId + Prediction)\n",
    "passenger_ids = pd.read_csv(\"test.csv\")[\"PassengerId\"]\n",
    "submission_df = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": test_predictions\n",
    "})\n",
    "\n",
    "# Display the full submission\n",
    "print(\"\\n--- Submission Preview ---\")\n",
    "print(submission_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
