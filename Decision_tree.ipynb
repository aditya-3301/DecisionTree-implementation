{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "from typing import Union\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Mapping 'Sex' column to binary values: 1 for male, 0 for female\n",
    "train_df[\"Sex\"] = train_df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "test_df[\"Sex\"] = test_df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "\n",
    "# Display basic information for the training and test datasets\n",
    "def display_basic_info(df: pd.DataFrame, name: str):\n",
    "    print(f\"--- {name} Dataset ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Data Types:\\n{df.dtypes}\")\n",
    "    print(f\"Missing Values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Statistical Summary:\\n{df.describe()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Explore the datasets\n",
    "display_basic_info(train_df, \"Train\")\n",
    "display_basic_info(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop([\"PassengerId\",\"Ticket\",\"Cabin\"],axis = 1)\n",
    "test_df=test_df.drop([\"PassengerId\",\"Ticket\",\"Cabin\"],axis = 1)\n",
    "print(train_df.columns)\n",
    "print(test_df.columns)\n",
    "y=train_df[\"Survived\"]\n",
    "print(\"\\n\\n\\n\",train_df[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature for total family members aboard (including the passenger)\n",
    "train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
    "test_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n",
    "\n",
    "# Fill missing Age values with the median (to avoid bias from missing data)\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].median())\n",
    "\n",
    "\n",
    "# Categorize passengers into age groups for better generalization\n",
    "train_df[\"AgeGroup\"] = pd.cut(train_df[\"Age\"], bins=[0, 12, 18, 35, 60, 80],\n",
    "                              labels=[\"Child\", \"Teen\", \"YoungAdult\", \"Adult\", \"Senior\"])\n",
    "test_df[\"AgeGroup\"] = pd.cut(test_df[\"Age\"], bins=[0, 12, 18, 35, 60, 80],\n",
    "                             labels=[\"Child\", \"Teen\", \"YoungAdult\", \"Adult\", \"Senior\"])\n",
    "\n",
    "# Extract title from the Name column\n",
    "def extract_title(name):\n",
    "    if \"Mr.\" in name:\n",
    "        return \"Mr.\"\n",
    "    elif \"Mrs.\" in name:\n",
    "        return \"Mrs.\"\n",
    "    elif \"Miss\" in name:\n",
    "        return \"Miss\"\n",
    "    elif \"Ms.\" in name:\n",
    "        return \"Ms.\"\n",
    "    elif \"Master\" in name:\n",
    "        return \"Master.\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply title extraction to Name column\n",
    "train_df[\"Name\"] = train_df[\"Name\"].apply(extract_title)\n",
    "\n",
    "# Create a feature that flags passengers traveling alone\n",
    "train_df[\"IsAlone\"] = (train_df[\"FamilySize\"] == 1).astype(int)\n",
    "test_df[\"IsAlone\"] = (test_df[\"FamilySize\"] == 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, criterion='gini') -> None:\n",
    "        self.max_depth = max_depth  # Max depth of the tree\n",
    "        self.min_samples_split = min_samples_split  # Min samples required to split\n",
    "        self.tree = None  # Final tree structure\n",
    "\n",
    "    def gini_impurity(self, y: list) -> float:\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        gini = 1 - sum((count / total) ** 2 for count in counts.values())\n",
    "        return gini\n",
    "\n",
    "    def get_thresholds(self, feature_column: list) -> list: \n",
    "        # Remove None, NaN, and \"Unknown\" values from feature_column\n",
    "        cleaned = [x for x in feature_column if x is not None and pd.notna(x) and x != \"Unknown\"]\n",
    "\n",
    "        thresholds = []\n",
    "        if len(cleaned) == 0:\n",
    "            return thresholds  # No valid values, return empty list\n",
    "\n",
    "        # Check if all cleaned values are numeric (int or float)\n",
    "        if all(isinstance(x, (int, float)) for x in cleaned):\n",
    "            # For numeric: use midpoints between sorted unique values\n",
    "            unique_values = sorted(set(cleaned))\n",
    "            for i in range(len(unique_values) - 1):\n",
    "                midpoint = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "                thresholds.append(midpoint)\n",
    "            return thresholds\n",
    "        else:\n",
    "            # For categorical: use unique categories sorted alphabetically\n",
    "            unique_categories = sorted(set(cleaned))\n",
    "            return unique_categories\n",
    "\n",
    "    def split_data(self, passengers_df: pd.DataFrame, survived: list, feature: str, threshold: float) -> tuple:\n",
    "        # Split data into left and right groups based on feature and threshold\n",
    "        passengers = passengers_df.to_dict(orient='records')\n",
    "        left_pass, left_survived = [], []\n",
    "        right_pass, right_survived = [], []\n",
    "\n",
    "        if isinstance(threshold, (int, float)):\n",
    "            for i in range(len(passengers)):\n",
    "                if passengers[i][feature] <= threshold:\n",
    "                    left_pass.append(passengers[i])\n",
    "                    left_survived.append(survived[i])\n",
    "                else:\n",
    "                    right_pass.append(passengers[i])\n",
    "                    right_survived.append(survived[i])\n",
    "        else:\n",
    "            for i in range(len(passengers)):\n",
    "                if passengers[i][feature] == threshold:\n",
    "                    right_pass.append(passengers[i])\n",
    "                    right_survived.append(survived[i])\n",
    "                else:\n",
    "                    left_pass.append(passengers[i])\n",
    "                    left_survived.append(survived[i])\n",
    "\n",
    "        return left_pass, left_survived, right_pass, right_survived\n",
    "\n",
    "    def information_gain(self, passengers_df: pd.DataFrame, survived: list, feature: str, threshold: float) -> float:\n",
    "        # Calculate info gain for a specific feature-threshold split\n",
    "        parent_gini = self.gini_impurity(survived)\n",
    "\n",
    "        left_pass, left_survived, right_pass, right_survived = self.split_data(\n",
    "            passengers_df, survived, feature, threshold)\n",
    "\n",
    "        w_left = len(left_survived) / len(survived)\n",
    "        w_right = len(right_survived) / len(survived)\n",
    "\n",
    "        g_left = self.gini_impurity(left_survived)\n",
    "        g_right = self.gini_impurity(right_survived)\n",
    "\n",
    "        info_gain = parent_gini - (w_left * g_left + w_right * g_right)\n",
    "        return info_gain\n",
    "\n",
    "    def best_split(self, passengers_df: pd.DataFrame, survived: list) -> Union[str, float, float]:\n",
    "        # Find the best feature and threshold to split on\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_info_gain = -float('inf')\n",
    "\n",
    "        for feature in passengers_df.columns:\n",
    "            thresholds = self.get_thresholds(passengers_df[feature].values)\n",
    "            for threshold in thresholds:\n",
    "                temp_info = self.information_gain(passengers_df, survived, feature, threshold)\n",
    "                if temp_info > best_info_gain:\n",
    "                    best_info_gain = temp_info\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_info_gain\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y, depth=0):\n",
    "        y=list(y)\n",
    "        # Train the tree recursively\n",
    "\n",
    "        # Stop if all labels are the same\n",
    "        if len(set(y)) == 1:\n",
    "            return {\"type\": \"leaf\", \"prediction\": y[0]} \n",
    "\n",
    "        # Stop if tree depth exceeded\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            y_list = list(y)\n",
    "            prediction = max(set(y_list), key=y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "\n",
    "        # Stop if too few samples to split\n",
    "        if len(y) < self.min_samples_split:\n",
    "            y_list = list(y)\n",
    "            prediction = max(set(y_list), key=y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "\n",
    "        # Find best feature and threshold\n",
    "        feature, threshold, gain = self.best_split(X, y)\n",
    "\n",
    "        # Split data\n",
    "        left_pass, left_y, right_pass, right_y = self.split_data(X, y, feature, threshold)\n",
    "\n",
    "        # If any side is empty, make a leaf with majority class\n",
    "        if len(left_y) == 0:\n",
    "            right_y_list = list(right_y)\n",
    "            prediction = max(set(right_y_list), key=right_y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "        if len(right_y) == 0:\n",
    "            left_y_list = list(left_y)\n",
    "            prediction = max(set(left_y_list), key=left_y_list.count)\n",
    "            return {\"type\": \"leaf\", \"prediction\": prediction}\n",
    "\n",
    "        # Recursively build left and right branches\n",
    "        left_pass = pd.DataFrame(left_pass)\n",
    "        right_pass = pd.DataFrame(right_pass)\n",
    "\n",
    "        left_branch = self.fit(left_pass, left_y, depth + 1)\n",
    "        right_branch = self.fit(right_pass, right_y, depth + 1)\n",
    "\n",
    "        node = {\n",
    "            \"type\": \"node\",\n",
    "            \"feature\": feature,\n",
    "            \"threshold\": threshold,\n",
    "            \"left\": left_branch,\n",
    "            \"right\": right_branch\n",
    "        }\n",
    "\n",
    "        if depth == 0:\n",
    "            self.tree = node  # Save the root of the tree\n",
    "        return node\n",
    "\n",
    "\n",
    "    def predict_sample(self, x: dict):\n",
    "        # Predict the label for a single sample\n",
    "        node = self.tree\n",
    "        while node[\"type\"] != \"leaf\":\n",
    "            feature = node[\"feature\"]\n",
    "            threshold = node[\"threshold\"]\n",
    "\n",
    "            if isinstance(threshold, (int, float)):\n",
    "                if x[feature] <= threshold:\n",
    "                    node = node[\"left\"]\n",
    "                else:\n",
    "                    node = node[\"right\"]\n",
    "            else:\n",
    "                if x[feature] == threshold:\n",
    "                    node = node[\"right\"]\n",
    "                else:\n",
    "                    node = node[\"left\"]\n",
    "\n",
    "        return node[\"prediction\"]\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        # Predict labels for all samples\n",
    "        return [self.predict_sample(row) for _, row in X.iterrows()]\n",
    "\n",
    "X=train_df.drop([\"Survived\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8bc2a",
   "metadata": {},
   "source": [
    "Accuracy for first 29 height Trees are:\n",
    "\n",
    "[0.782, 0.76, 0.804, 0.832, 0.827, 0.827, 0.799, 0.788, 0.777, 0.782, 0.793, 0.765, 0.76, 0.771, 0.771, 0.765, 0.765, 0.76, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765]\n",
    "\n",
    "![alt text](7b4c980b-388c-4f2e-888b-698413d113f3-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=None, min_samples_split=2, max_features='sqrt'):\n",
    "        # Number of trees in the forest\n",
    "        self.n_trees = n_trees  \n",
    "        self.max_depth = max_depth  # Maximum depth of each tree\n",
    "        self.min_samples_split = min_samples_split  # Min samples to split a node\n",
    "        self.max_features = max_features  # How many features to consider at each split\n",
    "        self.trees = []  # List to hold all decision trees\n",
    "\n",
    "    def bootstrap_sample(self, X, y):\n",
    "        # Create a bootstrap sample (random sample with replacement)\n",
    "        n_samples = X.shape[0]\n",
    "        sample_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        X_sample = X.iloc[sample_indices]\n",
    "        y_sample = y.iloc[sample_indices].tolist() \n",
    "        return X_sample, y_sample\n",
    "\n",
    "    def random_feature_selection(self, total_features):\n",
    "        # Select a random subset of features to consider at each split\n",
    "        if self.max_features == 'sqrt':\n",
    "            num_features = int(sqrt(total_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            num_features = int(np.log2(total_features))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            num_features = self.max_features\n",
    "        else:\n",
    "            num_features = total_features  # Use all features if no valid option\n",
    "        \n",
    "        # Randomly pick feature indices without replacement\n",
    "        selected_features = np.random.choice(total_features, size=num_features, replace=False)\n",
    "        return selected_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Build the forest by training multiple decision trees\n",
    "        self.trees = []\n",
    "        total_features = X.shape[1]\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            # Create a new decision tree\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "\n",
    "            # Get bootstrap sample of data\n",
    "            X_sample, y_sample = self.bootstrap_sample(X, y)\n",
    "\n",
    "            # Randomly select features for this tree\n",
    "            feature_indices = self.random_feature_selection(total_features)\n",
    "            features = X.columns[feature_indices]\n",
    "\n",
    "            # Train the tree on the sample with selected features\n",
    "            tree.fit(X_sample[features], y_sample)\n",
    "\n",
    "            # Save features used by this tree (needed for prediction)\n",
    "            tree.features = features\n",
    "\n",
    "            # Add the trained tree to the forest\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict class for each sample by majority vote from all trees\n",
    "        all_tree_predictions = []\n",
    "\n",
    "        for tree in self.trees:\n",
    "            # Predict using only features this tree was trained on\n",
    "            predictions = tree.predict(X[tree.features])\n",
    "            all_tree_predictions.append(predictions)\n",
    "\n",
    "        # Transpose to group predictions by sample\n",
    "        all_tree_predictions = np.array(all_tree_predictions).T\n",
    "\n",
    "        final_predictions = []\n",
    "\n",
    "        for sample_predictions in all_tree_predictions:\n",
    "            # Count votes and pick the most common class\n",
    "            vote_counts = Counter(sample_predictions)\n",
    "            majority_vote = vote_counts.most_common(1)[0][0]\n",
    "            final_predictions.append(majority_vote)\n",
    "\n",
    "        return final_predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Predict probability distribution of classes for each sample\n",
    "        all_tree_predictions = []\n",
    "\n",
    "        for tree in self.trees:\n",
    "            predictions = tree.predict(X[tree.features])\n",
    "            all_tree_predictions.append(predictions)\n",
    "\n",
    "        all_tree_predictions = np.array(all_tree_predictions).T\n",
    "\n",
    "        probability_predictions = []\n",
    "\n",
    "        for sample_predictions in all_tree_predictions:\n",
    "            counts = Counter(sample_predictions)\n",
    "            total_votes = len(sample_predictions)\n",
    "\n",
    "            # Calculate proportion of votes for each class\n",
    "            class_probabilities = {cls: count / total_votes for cls, count in counts.items()}\n",
    "            probability_predictions.append(class_probabilities)\n",
    "\n",
    "        return probability_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69198ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the hyperparameters to train and evaluate the model (Already done)\n",
    "# BEST PARAMETERS FOUND SO FAR: Trees: 50, Max Depth: 4, Min Samples Split: 5 --> Accuracy: 0.8156]\n",
    "\n",
    "# for n_trees in n_trees_options:\n",
    "#     for max_depth in max_depth_options:\n",
    "#         for min_samples_split in min_samples_split_options:\n",
    "#             rf = RandomForest(\n",
    "#                 n_trees=n_trees,\n",
    "#                 max_depth=max_depth,\n",
    "#                 min_samples_split=min_samples_split,\n",
    "#                 max_features='sqrt'\n",
    "#             )\n",
    "#             rf.fit(X_train, y_train)\n",
    "#             preds = rf.predict(X_val)\n",
    "#             accuracy = sum(pred == true for pred, true in zip(preds, y_val)) / len(y_val)\n",
    "#             print(f\"Trees: {n_trees}, Max Depth: {max_depth}, Min Samples Split: {min_samples_split} Accuracy: {accuracy:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the full training set (features and labels)\n",
    "X_train_full = train_df.drop(\"Survived\", axis=1)  # Features\n",
    "y_train_full = train_df[\"Survived\"]               # Target\n",
    "\n",
    "# Prepare the test set (make sure it matches training features)\n",
    "X_test = test_df[X_train_full.columns]\n",
    "\n",
    "# Initialize the best Random Forest model found from tuning\n",
    "rf_best = RandomForest(\n",
    "    n_trees=50,\n",
    "    max_depth=4,\n",
    "    min_samples_split=5,\n",
    "    max_features='sqrt'\n",
    ")\n",
    "\n",
    "# Train the model on the entire training dataset\n",
    "rf_best.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Print the predictions as a submission format (PassengerId + Prediction)\n",
    "passenger_ids = pd.read_csv(\"test.csv\")[\"PassengerId\"]\n",
    "submission_df = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": test_predictions\n",
    "})\n",
    "\n",
    "# Display the full submission\n",
    "print(\"\\n--- Submission Preview ---\")\n",
    "print(submission_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
